{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, sys, urllib, gzip\n",
      "import cPickle as pickle\n",
      "sys.setrecursionlimit(10000)\n",
      "import glob\n",
      "from IPython.display import clear_output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import numpy as np\n",
      "from IPython.display import Image as IPImage\n",
      "from PIL import Image"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lasagne.layers import get_output, InputLayer, DenseLayer, Upscale2DLayer, ReshapeLayer\n",
      "from lasagne.nonlinearities import rectify, leaky_rectify, tanh\n",
      "from lasagne.updates import nesterov_momentum\n",
      "from lasagne.objectives import categorical_crossentropy\n",
      "from nolearn.lasagne import NeuralNet, BatchIterator, PrintLayerInfo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using gpu device 0: GRID K520 (CNMeM is disabled)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lasagne.layers import Conv2DLayer as Conv2DLayerSlow\n",
      "from lasagne.layers import MaxPool2DLayer as MaxPool2DLayerSlow\n",
      "try:\n",
      "    from lasagne.layers.dnn import Conv2DDNNLayer as Conv2DLayer\n",
      "    from lasagne.layers.dnn import MaxPool2DDNNLayer as MaxPool2DLayer\n",
      "    print 'Using cuda_convnet (faster)'\n",
      "except ImportError:\n",
      "    from lasagne.layers import Conv2DLayer as Conv2DLayerFast\n",
      "    from lasagne.layers import MaxPool2DLayer as MaxPool2DLayerFast\n",
      "    print 'Using lasagne.layers (slower)'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using cuda_convnet (faster)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ch = 1\n",
      "im = Image.open('../gremlins_gray/out1.png')\n",
      "print im.size\n",
      "if ch == 1:\n",
      "    im = im.convert('L')\n",
      "X = np.asarray(im.getdata()).reshape(112,112,ch).transpose(2,1,0) / 255.\n",
      "X = X.reshape(-1,ch,112,112).astype(float32)\n",
      "n = 0\n",
      "for filename in glob.glob(\"../gremlins_gray/*.png\"):\n",
      "    n = n + 1\n",
      "    im = Image.open(filename)\n",
      "    Xim = np.asarray(im.getdata()).reshape(112,112,ch).transpose(2,1,0) / 255.\n",
      "    Xim = Xim.reshape(-1,ch,112,112).astype(float32)\n",
      "    X = np.concatenate((X, Xim), axis=0).astype(float32)\n",
      "    if n==5000:\n",
      "        break\n",
      "    \n",
      "print 'X type and shape:', X.dtype, X.shape\n",
      "print 'X.min():', X.min()\n",
      "print 'X.max():', X.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(112, 112)\n",
        "X type and shape:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " float32 (5001, 1, 112, 112)\n",
        "X.min(): 0.0\n",
        "X.max(): 1.0\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# reshape from (50000, 784) to 4D tensor (50000, 1, 28, 28)\n",
      "X = np.reshape(X, (-1, 1, 112, 112)).astype(float32)\n",
      "print 'X type and shape:', X.dtype, X.shape\n",
      "print 'X.min():', X.min()\n",
      "print 'X.max():', X.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X type and shape: float32 (5001, 1, 112, 112)\n",
        "X.min(): 0.0\n",
        "X.max(): "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# we need our target to be 1 dimensional\n",
      "X_out = X.reshape((X.shape[0], -1)).astype(float32)\n",
      "print 'X_out:', X_out.dtype, X_out.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X_out: float32 (5001, 12544)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conv_num_filters = 32\n",
      "filter_size = 5\n",
      "pool_size = 2\n",
      "encode_size = 32\n",
      "dense_mid_size = 128\n",
      "pad_in = 'valid'\n",
      "pad_out = 'full'\n",
      "layers = [\n",
      "    (InputLayer, {'shape': (None, X.shape[1], X.shape[2], X.shape[3])}), \n",
      "    (Conv2DLayer, {'num_filters': conv_num_filters, 'filter_size': filter_size, 'pad': pad_in}),\n",
      "    (Conv2DLayer, {'num_filters': conv_num_filters, 'filter_size': filter_size, 'pad': pad_in}),\n",
      "    (MaxPool2DLayer, {'pool_size': pool_size}),\n",
      "    (Conv2DLayer, {'num_filters': conv_num_filters/2, 'filter_size': filter_size, 'pad': pad_in}),\n",
      "    (MaxPool2DLayer, {'pool_size': pool_size}),\n",
      "    (ReshapeLayer, {'shape': (([0], -1))}),\n",
      "    (DenseLayer, {'num_units': dense_mid_size}),\n",
      "    (DenseLayer, {'name': 'encode', 'num_units': encode_size}),\n",
      "    (DenseLayer, {'num_units': dense_mid_size}),\n",
      "    (DenseLayer, {'num_units': 9216}),\n",
      "    (ReshapeLayer, {'shape': (([0], conv_num_filters/2, 24, 24))}),\n",
      "    (Upscale2DLayer, {'scale_factor': pool_size}),\n",
      "    (Conv2DLayer, {'num_filters': conv_num_filters, 'filter_size': filter_size, 'pad': pad_out}),\n",
      "    (Upscale2DLayer, {'scale_factor': pool_size}),\n",
      "    (Conv2DLayerSlow, {'num_filters': conv_num_filters, 'filter_size': filter_size, 'pad': pad_out}),\n",
      "    (Conv2DLayerSlow, {'num_filters': 1, 'filter_size': filter_size, 'pad': pad_out}),\n",
      "    (ReshapeLayer, {'shape': (([0], -1))}),\n",
      "]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ae = NeuralNet(\n",
      "    layers=layers,\n",
      "    max_epochs=40,\n",
      "    \n",
      "    update=nesterov_momentum,\n",
      "    update_learning_rate=0.01,\n",
      "    update_momentum=0.975,\n",
      "    \n",
      "    regression=True,\n",
      "    verbose=1\n",
      ")\n",
      "# ae.initialize()\n",
      "# PrintLayerInfo()(ae)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ae.fit(X, X_out)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "# Neural Network with 2455537 learnable parameters\n",
        "\n",
        "## Layer information\n",
        "\n",
        "  #  name           size\n",
        "---  -------------  ----------\n",
        "  0  input0         1x112x112\n",
        "  1  conv2ddnn1     32x108x108\n",
        "  2  conv2ddnn2     32x104x104\n",
        "  3  maxpool2ddnn3  32x52x52\n",
        "  4  conv2ddnn4     16x48x48\n",
        "  5  maxpool2ddnn5  16x24x24\n",
        "  6  reshape6       9216\n",
        "  7  dense7         128\n",
        "  8  encode         32\n",
        "  9  dense9         128\n",
        " 10  dense10        9216\n",
        " 11  reshape11      16x24x24\n",
        " 12  upscale2d12    16x48x48\n",
        " 13  conv2ddnn13    32x52x52\n",
        " 14  upscale2d14    32x104x104\n",
        " 15  conv2d15       32x108x108\n",
        " 16  conv2d16       1x112x112\n",
        " 17  reshape17      12544\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  epoch    train loss    valid loss    train/val  dur\n",
        "-------  ------------  ------------  -----------  ------\n",
        "      1       \u001b[36m0.03838\u001b[0m       \u001b[32m0.03244\u001b[0m      1.18289  47.74s\n"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nolearn.lasagne.visualize import plot_loss\n",
      "plot_loss(ae)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!mkdir mnist\n",
      "# ae.save_params_to('mnist/conv_ae.np')\n",
      "pickle.dump(ae, open('mnist/conv_ae.pkl','w'))\n",
      "# ae = pickle.load(open('mnist/conv_ae.pkl','r'))\n",
      "# ae.layers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_pred = ae.predict(X).reshape(-1, 112, 112)\n",
      "X_pred = np.rint(256. * X_pred).astype(int)\n",
      "X_pred = np.clip(X_pred, a_min = 0, a_max = 255)\n",
      "X_pred = X_pred.astype('uint8')\n",
      "print X_pred.shape , X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!mkdir -p data\n",
      "!mkdir -p montage"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###  show random inputs / outputs side by side\n",
      "\n",
      "def get_picture_array(X, rescale=4):\n",
      "    array = X.reshape(112,112)\n",
      "    array = np.clip(array, a_min = 0, a_max = 255)\n",
      "    return  array.repeat(rescale, axis = 0).repeat(rescale, axis = 1).astype(np.uint8())\n",
      "\n",
      "def compare_images(index):\n",
      "    print index\n",
      "    original_image = Image.fromarray(get_picture_array(255 * X[index]))\n",
      "    new_size = (original_image.size[0] * 2, original_image.size[1])\n",
      "    new_im = Image.new('L', new_size)\n",
      "    new_im.paste(original_image, (0,0))\n",
      "    rec_image = Image.fromarray(get_picture_array(X_pred[index]))\n",
      "    new_im.paste(rec_image, (original_image.size[0],0))\n",
      "    new_im.save('data/test.png', format=\"PNG\")\n",
      "    return IPImage('data/test.png')\n",
      "\n",
      "compare_images(900)\n",
      "# compare_images(np.random.randint(50000))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## we find the encode layer from our ae, and use it to define an encoding function\n",
      "\n",
      "def get_layer_by_name(net, name):\n",
      "    for i, layer in enumerate(net.get_all_layers()):\n",
      "        if layer.name == name:\n",
      "            return layer, i\n",
      "    return None, None\n",
      "encode_layer, encode_layer_index = get_layer_by_name(ae, 'encode')\n",
      "\n",
      "def encode_input(encode_layer, X):\n",
      "    return get_output(encode_layer, inputs=X).eval()\n",
      "\n",
      "X_encoded = encode_input(encode_layer, X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "next_layer = ae.get_all_layers()[encode_layer_index + 1]\n",
      "final_layer = ae.get_all_layers()[-1]\n",
      "new_layer = InputLayer(shape=(None, encode_layer.num_units))\n",
      "\n",
      "# N.B after we do this, we won't be able to use the original autoencoder , as the layers are broken up\n",
      "next_layer.input_layer = new_layer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    }
   ],
   "metadata": {}
  }
 ]
}