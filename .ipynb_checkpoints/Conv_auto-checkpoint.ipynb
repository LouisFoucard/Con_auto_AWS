{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, sys, urllib, gzip\n",
      "import cPickle as pickle\n",
      "sys.setrecursionlimit(10000)\n",
      "import glob\n",
      "from IPython.display import clear_output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import numpy as np\n",
      "from IPython.display import Image as IPImage\n",
      "from PIL import Image"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lasagne.layers import get_output, InputLayer, DenseLayer, Upscale2DLayer, ReshapeLayer\n",
      "from lasagne.nonlinearities import rectify, leaky_rectify, tanh\n",
      "from lasagne.updates import nesterov_momentum\n",
      "from lasagne.objectives import categorical_crossentropy\n",
      "from nolearn.lasagne import NeuralNet, BatchIterator, PrintLayerInfo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lasagne.layers import Conv2DLayer as Conv2DLayerSlow\n",
      "from lasagne.layers import MaxPool2DLayer as MaxPool2DLayerSlow\n",
      "try:\n",
      "    from lasagne.layers.dnn import Conv2DDNNLayer as Conv2DLayer\n",
      "    from lasagne.layers.dnn import MaxPool2DDNNLayer as MaxPool2DLayer\n",
      "    print 'Using cuda_convnet (faster)'\n",
      "except ImportError:\n",
      "    from lasagne.layers import Conv2DLayer as Conv2DLayerFast\n",
      "    from lasagne.layers import MaxPool2DLayer as MaxPool2DLayerFast\n",
      "    print 'Using lasagne.layers (slower)'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using cuda_convnet (faster)\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ch = 1\n",
      "im = Image.open('../gremlins_gray/out1.png')\n",
      "print im.size\n",
      "if ch == 1:\n",
      "    im = im.convert('L')\n",
      "X = np.asarray(im.getdata()).reshape(112,112,ch).transpose(2,1,0) / 255.\n",
      "X = X.reshape(-1,ch,112,112).astype(float32)\n",
      "n = 0\n",
      "for filename in glob.glob(\"../gremlins_gray/*.png\"):\n",
      "    n = n + 1\n",
      "    im = Image.open(filename)\n",
      "    Xim = np.asarray(im.getdata()).reshape(112,112,ch).transpose(2,1,0) / 255.\n",
      "    Xim = Xim.reshape(-1,ch,112,112).astype(float32)\n",
      "    X = np.concatenate((X, Xim), axis=0).astype(float32)\n",
      "    if n==5000:\n",
      "        break\n",
      "    \n",
      "print 'X type and shape:', X.dtype, X.shape\n",
      "print 'X.min():', X.min()\n",
      "print 'X.max():', X.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(112, 112)\n",
        "X type and shape:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " float32 (5001, 1, 112, 112)\n",
        "X.min(): 0.0\n",
        "X.max(): 1.0\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# reshape from (50000, 784) to 4D tensor (50000, 1, 28, 28)\n",
      "X = np.reshape(X, (-1, 1, 112, 112)).astype(float32)\n",
      "print 'X type and shape:', X.dtype, X.shape\n",
      "print 'X.min():', X.min()\n",
      "print 'X.max():', X.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X type and shape: float32 (5001, 1, 112, 112)\n",
        "X.min(): 0.0\n",
        "X.max(): "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# we need our target to be 1 dimensional\n",
      "X_out = X.reshape((X.shape[0], -1)).astype(float32)\n",
      "print 'X_out:', X_out.dtype, X_out.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X_out: float32 (5001, 12544)\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conv_num_filters = 16\n",
      "filter_size = 3\n",
      "pool_size = 2\n",
      "encode_size = 16\n",
      "dense_mid_size = 128\n",
      "pad_in = 'valid'\n",
      "pad_out = 'full'\n",
      "layers = [\n",
      "    (InputLayer, {'shape': (None, X.shape[1], X.shape[2], X.shape[3])}), \n",
      "    (Conv2DLayer, {'num_filters': conv_num_filters, 'filter_size': filter_size, 'pad': pad_in}),\n",
      "    (Conv2DLayer, {'num_filters': conv_num_filters, 'filter_size': filter_size, 'pad': pad_in}),\n",
      "    (MaxPool2DLayer, {'pool_size': pool_size}),\n",
      "    (Conv2DLayer, {'num_filters': 2*conv_num_filters, 'filter_size': filter_size, 'pad': pad_in}),\n",
      "    (MaxPool2DLayer, {'pool_size': pool_size}),\n",
      "    (ReshapeLayer, {'shape': (([0], -1))}),\n",
      "    (DenseLayer, {'num_units': dense_mid_size}),\n",
      "    (DenseLayer, {'name': 'encode', 'num_units': encode_size}),\n",
      "    (DenseLayer, {'num_units': dense_mid_size}),\n",
      "    (DenseLayer, {'num_units': 21632}),\n",
      "    (ReshapeLayer, {'shape': (([0], 2*conv_num_filters, 26, 26))}),\n",
      "    (Upscale2DLayer, {'scale_factor': pool_size}),\n",
      "    (Conv2DLayer, {'num_filters': conv_num_filters, 'filter_size': filter_size, 'pad': pad_out}),\n",
      "    (Upscale2DLayer, {'scale_factor': pool_size}),\n",
      "    (Conv2DLayerSlow, {'num_filters': conv_num_filters, 'filter_size': filter_size, 'pad': pad_out}),\n",
      "    (Conv2DLayerSlow, {'num_filters': 1, 'filter_size': filter_size, 'pad': pad_out}),\n",
      "    (ReshapeLayer, {'shape': (([0], -1))}),\n",
      "]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ae = NeuralNet(\n",
      "    layers=layers,\n",
      "    max_epochs=20,\n",
      "    \n",
      "    update=nesterov_momentum,\n",
      "    update_learning_rate=0.01,\n",
      "    update_momentum=0.975,\n",
      "    \n",
      "    regression=True,\n",
      "    verbose=1\n",
      ")\n",
      "# ae.initialize()\n",
      "# PrintLayerInfo()(ae)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ae.fit(X, X_out)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "# Neural Network with 2890673 learnable parameters\n",
        "\n",
        "## Layer information\n",
        "\n",
        "  #  name           size\n",
        "---  -------------  ----------\n",
        "  0  input0         1x112x112\n",
        "  1  conv2ddnn1     16x110x110\n",
        "  2  conv2ddnn2     16x108x108\n",
        "  3  maxpool2ddnn3  16x54x54\n",
        "  4  conv2ddnn4     32x52x52\n",
        "  5  maxpool2ddnn5  32x26x26\n",
        "  6  reshape6       21632\n",
        "  7  dense7         128\n",
        "  8  encode         16\n",
        "  9  dense9         128\n",
        " 10  dense10        800\n",
        " 11  reshape11      32x5x5\n",
        " 12  upscale2d12    32x10x10\n",
        " 13  conv2ddnn13    16x12x12\n",
        " 14  upscale2d14    16x24x24\n",
        " 15  conv2d15       16x26x26\n",
        " 16  conv2d16       1x28x28\n",
        " 17  reshape17      784\n",
        "\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "GpuElemwise. Input dimension mis-match. Input 1 (indices start at 0) has shape[1] == 12544, but the output's size on that axis is 784.\nApply node that caused the error: GpuElemwise{Sub}[(0, 0)](GpuReshape{2}.0, GpuFromHost.0)\nToposort index: 227\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(128, 784), (128, 12544)]\nInputs strides: [(784, 1), (12544, 1)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuCAReduce{pre=sqr,red=add}{1,1}(GpuElemwise{Sub}[(0, 0)].0), GpuElemwise{Composite{((i0 * i1) / i2)}}[(0, 1)](CudaNdarrayConstant{[[ 2.]]}, GpuElemwise{Sub}[(0, 0)].0, GpuElemwise{mul,no_inplace}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-31-9bf5e27d5b08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, epochs)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(self, X, y, epochs)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_iterator_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 batch_train_loss = self.apply_batch_func(\n\u001b[0;32m--> 514\u001b[0;31m                     self.train_iter_, Xb, yb)\n\u001b[0m\u001b[1;32m    515\u001b[0m                 \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_train_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36mapply_batch_func\u001b[0;34m(func, Xb, yb)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    872\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: GpuElemwise. Input dimension mis-match. Input 1 (indices start at 0) has shape[1] == 12544, but the output's size on that axis is 784.\nApply node that caused the error: GpuElemwise{Sub}[(0, 0)](GpuReshape{2}.0, GpuFromHost.0)\nToposort index: 227\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(128, 784), (128, 12544)]\nInputs strides: [(784, 1), (12544, 1)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuCAReduce{pre=sqr,red=add}{1,1}(GpuElemwise{Sub}[(0, 0)].0), GpuElemwise{Composite{((i0 * i1) / i2)}}[(0, 1)](CudaNdarrayConstant{[[ 2.]]}, GpuElemwise{Sub}[(0, 0)].0, GpuElemwise{mul,no_inplace}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nolearn.lasagne.visualize import plot_loss\n",
      "plot_loss(ae)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEPCAYAAACDTflkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nt/8HXAOPPAGPMjAAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fb80827c150>"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!mkdir mnist\n",
      "# ae.save_params_to('mnist/conv_ae.np')\n",
      "pickle.dump(ae, open('mnist/conv_ae.pkl','w'))\n",
      "# ae = pickle.load(open('mnist/conv_ae.pkl','r'))\n",
      "# ae.layers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_pred = ae.predict(X).reshape(-1, 112, 112)\n",
      "X_pred = np.rint(256. * X_pred).astype(int)\n",
      "X_pred = np.clip(X_pred, a_min = 0, a_max = 255)\n",
      "X_pred = X_pred.astype('uint8')\n",
      "print X_pred.shape , X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1001, 112, 112) (16016, 1, 28, 28)\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!mkdir -p data\n",
      "!mkdir -p montage"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###  show random inputs / outputs side by side\n",
      "\n",
      "def get_picture_array(X, rescale=4):\n",
      "    array = X.reshape(28,28)\n",
      "    array = np.clip(array, a_min = 0, a_max = 255)\n",
      "    return  array.repeat(rescale, axis = 0).repeat(rescale, axis = 1).astype(np.uint8())\n",
      "\n",
      "def compare_images(index):\n",
      "    print index\n",
      "    original_image = Image.fromarray(get_picture_array(255 * X[index]))\n",
      "    new_size = (original_image.size[0] * 2, original_image.size[1])\n",
      "    new_im = Image.new('L', new_size)\n",
      "    new_im.paste(original_image, (0,0))\n",
      "    rec_image = Image.fromarray(get_picture_array(X_pred[index]))\n",
      "    new_im.paste(rec_image, (original_image.size[0],0))\n",
      "    new_im.save('data/test.png', format=\"PNG\")\n",
      "    return IPImage('data/test.png')\n",
      "\n",
      "compare_images(2)\n",
      "# compare_images(np.random.randint(50000))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "total size of new array must be unchanged",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-20-37c34b2c353e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mIPImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/test.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mcompare_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;31m# compare_images(np.random.randint(50000))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-20-37c34b2c353e>\u001b[0m in \u001b[0;36mcompare_images\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompare_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moriginal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_picture_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mnew_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnew_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-20-37c34b2c353e>\u001b[0m in \u001b[0;36mget_picture_array\u001b[0;34m(X, rescale)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_picture_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m112\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m112\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m  \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: total size of new array must be unchanged"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## we find the encode layer from our ae, and use it to define an encoding function\n",
      "\n",
      "def get_layer_by_name(net, name):\n",
      "    for i, layer in enumerate(net.get_all_layers()):\n",
      "        if layer.name == name:\n",
      "            return layer, i\n",
      "    return None, None\n",
      "encode_layer, encode_layer_index = get_layer_by_name(ae, 'encode')\n",
      "\n",
      "def encode_input(encode_layer, X):\n",
      "    return get_output(encode_layer, inputs=X).eval()\n",
      "\n",
      "X_encoded = encode_input(encode_layer, X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "next_layer = ae.get_all_layers()[encode_layer_index + 1]\n",
      "final_layer = ae.get_all_layers()[-1]\n",
      "new_layer = InputLayer(shape=(None, encode_layer.num_units))\n",
      "\n",
      "# N.B after we do this, we won't be able to use the original autoencoder , as the layers are broken up\n",
      "next_layer.input_layer = new_layer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}